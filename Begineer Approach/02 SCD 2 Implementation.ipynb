{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c228157-85c1-4632-8423-d2959ef15962",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "-- Create dimension tables for SCD-2:\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS real_time_projects.ecommerce_historical.dim_customers (\n",
    "    customer_id STRING,\n",
    "    customer_unique_id STRING,\n",
    "    customer_zip_code_prefix INT,\n",
    "    customer_city STRING,\n",
    "    customer_state STRING,\n",
    "\n",
    "    effective_start_date DATE,\n",
    "    effective_end_date DATE,\n",
    "    is_active STRING\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS real_time_projects.ecommerce_historical.dim_products (\n",
    "    product_id STRING,\n",
    "    product_category_name STRING,\n",
    "    product_name_lenght INT,\n",
    "    product_description_lenght INT,\n",
    "    product_photos_qty INT,\n",
    "    product_weight_g INT,\n",
    "    product_length_cm INT,\n",
    "    product_height_cm INT,\n",
    "    product_width_cm INT,\n",
    "\n",
    "    effective_start_date DATE,\n",
    "    effective_end_date DATE,\n",
    "    is_active STRING\n",
    ")\n",
    "USING DELTA;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4bed381-7870-4218-9880-f11213b78e60",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Existing Customer Delta Table\n",
    "customers_src_df = spark.table(\"real_time_projects.ecommerce_historical.customers\")   # existing delta table\n",
    "\n",
    "# Create Customer Stage\n",
    "customer_stage_df = (\n",
    "    customers_src_df\n",
    "    .withColumn(\"effective_start_date\", current_date())\n",
    "    .withColumn(\"effective_end_date\", lit(\"9999-12-31\"))\n",
    "    .withColumn(\"is_active\", lit(\"Y\"))\n",
    ")\n",
    "\n",
    "# SCD-2 Merge Customer\n",
    "dim_customers = DeltaTable.forName(spark, \"real_time_projects.ecommerce_historical.dim_customers\")\n",
    "\n",
    "merge_condition = \"\"\"\n",
    "    t.customer_id = s.customer_id\n",
    "    AND t.is_active = 'Y'\n",
    "\"\"\"\n",
    "\n",
    "dim_customers.alias(\"t\").merge(\n",
    "    customer_stage_df.alias(\"s\"),\n",
    "    merge_condition\n",
    ").whenMatchedUpdate(\n",
    "    condition=\"\"\"\n",
    "        t.customer_unique_id <> s.customer_unique_id OR\n",
    "        t.customer_zip_code_prefix <> s.customer_zip_code_prefix OR\n",
    "        t.customer_city <> s.customer_city OR\n",
    "        t.customer_state <> s.customer_state\n",
    "    \"\"\",\n",
    "    set={\n",
    "        \"effective_end_date\": \"current_date()\",\n",
    "        \"is_active\": \"'N'\"\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values={\n",
    "        \"customer_id\": \"s.customer_id\",\n",
    "        \"customer_unique_id\": \"s.customer_unique_id\",\n",
    "        \"customer_zip_code_prefix\": \"s.customer_zip_code_prefix\",\n",
    "        \"customer_city\": \"s.customer_city\",\n",
    "        \"customer_state\": \"s.customer_state\",\n",
    "        \"effective_start_date\": \"s.effective_start_date\",\n",
    "        \"effective_end_date\": \"s.effective_end_date\",\n",
    "        \"is_active\": \"s.is_active\"\n",
    "    }\n",
    ").execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98548d06-10fc-4ae4-8ea5-ab3a8b72d7ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from real_time_projects.ecommerce_historical.dim_customers limit 10\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1f84188-7f97-4b20-8d56-219ebc3821f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "# Existing Customer Delta Table\n",
    "product_src_df = spark.table(\"real_time_projects.ecommerce_historical.products\")\n",
    "\n",
    "# Create Product Stage\n",
    "product_stage_df = (\n",
    "    product_src_df\n",
    "    .withColumn(\"effective_start_date\", current_date())\n",
    "    .withColumn(\"effective_end_date\", lit(\"9999-12-31\"))\n",
    "    .withColumn(\"is_active\", lit(\"Y\"))\n",
    ")\n",
    "\n",
    "# SCD-2 Merge Product\n",
    "dim_products = DeltaTable.forName(spark, \"real_time_projects.ecommerce_historical.dim_products\")\n",
    "\n",
    "merge_condition = \"\"\"\n",
    "    t.product_id = s.product_id\n",
    "    AND t.is_active = 'Y'\n",
    "\"\"\".\n",
    "\n",
    "dim_products.alias(\"t\").merge(\n",
    "    product_stage_df.alias(\"s\"),\n",
    "    merge_condition\n",
    ").whenMatchedUpdate(\n",
    "    condition=\"\"\"\n",
    "        t.product_category_name <> s.product_category_name OR\n",
    "        t.product_name_lenght <> s.product_name_lenght OR\n",
    "        t.product_description_lenght <> s.product_description_lenght OR\n",
    "        t.product_photos_qty <> s.product_photos_qty OR\n",
    "        t.product_weight_g <> s.product_weight_g OR\n",
    "        t.product_length_cm <> s.product_length_cm OR\n",
    "        t.product_height_cm <> s.product_height_cm OR\n",
    "        t.product_width_cm <> s.product_width_cm\n",
    "    \"\"\",\n",
    "    set={\n",
    "        \"effective_end_date\": \"current_date()\",\n",
    "        \"is_active\": \"'N'\"\n",
    "    }\n",
    ").whenNotMatchedInsert(\n",
    "    values={\n",
    "        \"product_id\": \"s.product_id\",\n",
    "        \"product_category_name\": \"s.product_category_name\",\n",
    "        \"product_name_lenght\": \"s.product_name_lenght\",\n",
    "        \"product_description_lenght\": \"s.product_description_lenght\",\n",
    "        \"product_photos_qty\": \"s.product_photos_qty\",\n",
    "        \"product_weight_g\": \"s.product_weight_g\",\n",
    "        \"product_length_cm\": \"s.product_length_cm\",\n",
    "        \"product_height_cm\": \"s.product_height_cm\",\n",
    "        \"product_width_cm\": \"s.product_width_cm\",\n",
    "        \"effective_start_date\": \"s.effective_start_date\",\n",
    "        \"effective_end_date\": \"s.effective_end_date\",\n",
    "        \"is_active\": \"s.is_active\"\n",
    "    }\n",
    ").execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d888d9-4cd5-4b9f-b2e6-3d82a4c232d9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from real_time_projects.ecommerce_historical.dim_products limit 10\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cc06c9ae-dcf7-4775-a4f8-1a72417f49cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "--Create Fact Sales Table\n",
    "CREATE TABLE IF NOT EXISTS real_time_projects.ecommerce_historical.fact_sales (\n",
    "    order_id STRING,\n",
    "    order_item_id STRING,\n",
    "    customer_id STRING,\n",
    "    product_id STRING,\n",
    "\n",
    "    order_purchase_timestamp TIMESTAMP,\n",
    "    order_date DATE,\n",
    "\n",
    "    price DOUBLE,\n",
    "    freight_value DOUBLE,\n",
    "    revenue DOUBLE,\n",
    "\n",
    "    customer_state STRING,\n",
    "    product_category_name STRING,\n",
    "\n",
    "    payment_value DOUBLE,\n",
    "    order_status STRING,\n",
    "    load_date DATE\n",
    ")\n",
    "USING DELTA;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ce4f345b-1966-407d-860c-a6423351b68a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Read Delta Table\n",
    "orders_df = spark.table(\"real_time_projects.ecommerce_historical.orders\")\n",
    "order_items_df = spark.table(\"real_time_projects.ecommerce_historical.order_items\")\n",
    "payments_df = spark.table(\"real_time_projects.ecommerce_historical.payments\")\n",
    "\n",
    "# Read Dimension Delta Table\n",
    "dim_customers_df = spark.table(\"real_time_projects.ecommerce_historical.dim_customers\").filter(\"is_active = 'Y'\")\n",
    "dim_products_df = spark.table(\"real_time_projects.ecommerce_historical.dim_products\").filter(\"is_active = 'Y'\")\n",
    "\n",
    "# Join order and order_items, ensure unique column names\n",
    "order_items_df = order_items_df.select(\n",
    "    \"order_id\",\n",
    "    col(\"order_item_id\").alias(\"order_item_id\"),\n",
    "    \"product_id\",\n",
    "    \"price\",\n",
    "    \"freight_value\"\n",
    ")\n",
    "\n",
    "# Join order and order_items \n",
    "sales_df = (\n",
    "    orders_df\n",
    "    .join(\n",
    "        order_items_df,\n",
    "        \"order_id\",\n",
    "        \"inner\"\n",
    "    ) \n",
    ")\n",
    "\n",
    "# Join customer & product dimensions\n",
    "sales_df = (\n",
    "    sales_df\n",
    "    .join(dim_customers_df, \"customer_id\", \"left\")\n",
    "    .join(dim_products_df, \"product_id\", \"left\")\n",
    ")\n",
    "\n",
    "# Join payments\n",
    "sales_df = sales_df.join(\n",
    "    payments_df.groupBy(\"order_id\")\n",
    "        .agg(sum(\"payment_value\").alias(\"payment_value\")),\n",
    "    \"order_id\",\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "#sales_df.printSchema()\n",
    "\n",
    "# Derive final columns\n",
    "fact_sales_df = (\n",
    "    sales_df\n",
    "    .select(\n",
    "        col(\"order_id\"),\n",
    "        col(\"order_item_id\"),\n",
    "        col(\"customer_id\"),\n",
    "        col(\"product_id\"),\n",
    "\n",
    "        col(\"order_purchase_timestamp\"),\n",
    "        to_date(\"order_purchase_timestamp\").alias(\"order_date\"),\n",
    "\n",
    "        col(\"price\"),\n",
    "        col(\"freight_value\"),\n",
    "        (col(\"price\") + col(\"freight_value\")).alias(\"revenue\"),\n",
    "\n",
    "        col(\"customer_state\"),\n",
    "        col(\"product_category_name\"),\n",
    "\n",
    "        col(\"payment_value\"),\n",
    "        col(\"order_status\"),\n",
    "\n",
    "        current_date().alias(\"load_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "fact_sales_df.printSchema()\n",
    "\n",
    "# Write to Delta Table\n",
    "fact_sales_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .saveAsTable(\"real_time_projects.ecommerce_historical.fact_sales\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b472017-4c2e-4030-b05a-baf50be0070e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.sql(\"select * from real_time_projects.ecommerce_historical.fact_sales limit 10\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd1a04c5-8e16-469d-8404-6cf7be6bfba9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT order_id, COUNT(*) \n",
    "FROM real_time_projects.ecommerce_historical.fact_sales\n",
    "GROUP BY order_id\n",
    "ORDER BY COUNT(*) DESC;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5248633862884743,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "02 SCD 2 Implementation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
